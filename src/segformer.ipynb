{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e42aa1",
   "metadata": {},
   "source": [
    "# U-Net Pretraining for FSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab222e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "import gc\n",
    "from PIL import Image\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "from collections import namedtuple, defaultdict\n",
    "import copy\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedGroupKFold\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd8db7a",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    seed          = 42\n",
    "    exp_name      = 'segformer'\n",
    "    model_name    = 'Segformer'\n",
    "    base_model    = 'segformer'\n",
    "    train_bs      = 32\n",
    "    valid_bs      = 2 * train_bs\n",
    "    image_size    = [224, 224]\n",
    "    comment       = f'model-{model_name}|base-{base_model}|dim-{image_size[0]}x{image_size[1]}'\n",
    "    epochs        = 10\n",
    "    learning_rate = 3e-4\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    wd            = 1e-6\n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    n_fold        = 5\n",
    "    num_classes   = 3\n",
    "    device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b5d220",
   "metadata": {},
   "source": [
    "# Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf487b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('>>> SEEDED <<<')\n",
    "\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c205278",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed-v0-no-empty/train_fold.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43833437",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d63d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    Extracted from: https://www.kaggle.com/code/paulorzp/run-length-encode-and-decode/script\n",
    "    \n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    Extracted from: https://www.kaggle.com/code/paulorzp/run-length-encode-and-decode/script\n",
    "    \n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c03f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch_sample(batch: Dict[str, torch.Tensor]) -> None:\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(batch['image'].permute(1,2,0).detach().numpy().astype(np.uint8))\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(batch['mask'].permute(1,2,0).detach().numpy().astype(np.uint8))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_batch(imgs, msks, size=3):\n",
    "    '''Extracted from: https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-train-pytorch'''\n",
    "    plt.figure(figsize=(5*5, 5))\n",
    "    for idx in range(size):\n",
    "        plt.subplot(1, 5, idx+1)\n",
    "        img = imgs[idx,].permute((1, 2, 0)).numpy()\n",
    "        img = img.astype('uint8')\n",
    "        msk = msks[idx,].permute((1, 2, 0)).numpy()\n",
    "        img = (0.5 * img + 0.5 * msk).astype(np.uint8)\n",
    "        plt.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7968328d",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f234c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UWMGIDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, mode: str = \"train\") -> None:\n",
    "        super(UWMGIDataset, self).__init__()\n",
    "        self.df = df\n",
    "        self.image_paths = df['image_paths'].to_list()\n",
    "        self.masks_paths = df['mask_paths'].to_list()\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.transforms = None\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            self.transforms = A.Compose([\n",
    "                A.Resize(height=config.image_size[0], width=config.image_size[1], interpolation=0),\n",
    "                A.Rotate(limit=90, p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.ColorJitter(p=0.5),\n",
    "#                 A.Normalize(),\n",
    "                ToTensorV2()\n",
    "            ], p=1.0)\n",
    "        elif self.mode == \"valid\":\n",
    "            self.transforms = A.Compose([\n",
    "#                 A.Resize(height=config.image_size[0], width=config.image_size[1], interpolation=0),\n",
    "#                 A.Normalize(),\n",
    "                ToTensorV2()\n",
    "            ], p=1.0)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"The case where mode={self.mode} has not been implemented try from ['train', 'valid']\")\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, ix: int) -> Dict[str, torch.Tensor]:\n",
    "        image_path = self.image_paths[ix]\n",
    "        mask_path = self.masks_paths[ix]\n",
    "        \n",
    "        image = np.array(Image.open(image_path))[:, :, :-1]\n",
    "        mask = np.array(Image.open(mask_path))[:, :, :-1]\n",
    "        \n",
    "        transformed = self.transforms(image=image, mask=mask)\n",
    "        image = torch.tensor(transformed['image'], dtype=torch.float32, device=config.device)\n",
    "        mask = torch.tensor(transformed['mask'], dtype=torch.float32, device=config.device)\n",
    "        mask = mask.permute(2, 0, 1)\n",
    "        return {\n",
    "            \"image\": image, \n",
    "            \"mask\": mask\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a817a14c",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66632dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloaders(fold: int) -> Tuple[DataLoader]:\n",
    "    train_df = df[df.kfold != fold]\n",
    "    valid_df = df[df.kfold == fold]\n",
    "    \n",
    "    train_dataset = UWMGIDataset(df=train_df, mode=\"train\")\n",
    "    valid_dataset = UWMGIDataset(df=valid_df, mode=\"valid\")\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_dataset, \n",
    "        batch_size=config.train_bs, \n",
    "        shuffle=True, \n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        dataset=valid_dataset, \n",
    "        batch_size=config.valid_bs, \n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c656e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = build_dataloaders(fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7527271",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "{k:v.shape for k,v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ff74a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1efef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegmentationModel, self).__init__()\n",
    "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            \"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\",\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        print(batch['image'].shape)\n",
    "        outputs = self.model(pixel_values=batch['image'])\n",
    "\n",
    "        upsampled_logits = F.interpolate(\n",
    "            outputs.logits,\n",
    "            size=batch['mask'].shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        return upsampled_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd239bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() -> nn.Module:\n",
    "    return SegmentationModel().to(config.device)\n",
    "\n",
    "def load_model(path: str):\n",
    "    model = build_model()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7b1ae",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9999beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_pred: torch.Tensor, y_true: torch.Tensor, thr: float = 0.5, eps: float = 1e-6) -> torch.Tensor:\n",
    "    y_true = y_true.to(dtype=torch.float32)\n",
    "    y_pred = (y_pred > thr).to(dtype=torch.float32)\n",
    "    intersection = 2.0 * (y_true * y_pred).sum() + eps\n",
    "    denominator  = y_pred.sum() + y_true.sum() + eps\n",
    "    dice = intersection / denominator\n",
    "    return dice.mean()\n",
    "\n",
    "def iou_coef(y_pred: torch.Tensor, y_true: torch.Tensor, thr: float = 0.5, eps: float = 1e-6) -> torch.Tensor:\n",
    "    y_true = y_true.to(dtype=torch.float32)\n",
    "    y_pred = (y_pred > thr).to(dtype=torch.float32)\n",
    "    intersection = (y_true * y_pred).sum() + eps\n",
    "    union        = y_true.sum() + y_pred.sum() - intersection + eps\n",
    "    return intersection / union\n",
    "\n",
    "bce_loss = smp.losses.SoftBCEWithLogitsLoss()\n",
    "tversky_loss = smp.losses.TverskyLoss(mode='multilabel')\n",
    "\n",
    "def loss_fn(y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    return 0.5*bce_loss(y_pred, y_true) + 0.5*tversky_loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af046ee",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer):\n",
    "    '''Extracted from: https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-train-pytorch'''\n",
    "    if config.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=config.T_max, \n",
    "                                                   eta_min=config.min_lr)\n",
    "    elif config.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=config.T_0, \n",
    "                                                             eta_min=config.min_lr)\n",
    "    elif config.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                   mode='min',\n",
    "                                                   factor=0.1,\n",
    "                                                   patience=7,\n",
    "                                                   threshold=0.0001,\n",
    "                                                   min_lr=config.min_lr,)\n",
    "    elif config.scheduer == 'ExponentialLR':\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
    "    elif config.scheduler == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93838d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "scheduler = get_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af688e7d",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module, \n",
    "    optimizer: optim, \n",
    "    scheduler: lr_scheduler, \n",
    "    dataloader: DataLoader\n",
    ") -> Tuple[float, float, float]:\n",
    "    model.train()\n",
    "    dataset_size = 0.0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    coef = {\n",
    "        'dice_coef': [],\n",
    "        'iou_coef': []\n",
    "    }\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, batch in pbar:\n",
    "        images, masks = batch['image'], batch['mask']\n",
    "        \n",
    "        y_pred = model.forward(images)\n",
    "        \n",
    "        loss = loss_fn(y_pred=y_pred, y_true=masks)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "        running_loss += loss.item() * images.shape[0]\n",
    "        dataset_size += images.shape[0]\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            coef['dice_coef'].append(dice_coef(y_pred=y_pred, y_true=masks))\n",
    "            coef['iou_coef'].append(iou_coef(y_pred=y_pred, y_true=masks))\n",
    "        \n",
    "        pbar.set_postfix(\n",
    "            train_loss=f'{epoch_loss:.3f}',\n",
    "            lr=f'{current_lr:.5f}',\n",
    "            dice=f'{np.mean(coef[\"dice_coef\"]):.3f}',\n",
    "            iou=f'{np.mean(coef[\"iou_coef\"]):.3f}',\n",
    "        )\n",
    "    \n",
    "    return epoch_loss, np.mean(coef['dice_coef']), np.mean(coef['iou_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aec47d",
   "metadata": {},
   "source": [
    "# Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc88ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(\n",
    "    model: nn.Module, \n",
    "    dataloader: DataLoader\n",
    ") -> Tuple[float, float, float]:\n",
    "    model.eval()\n",
    "    dataset_size = 0.0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    coef = {\n",
    "        'dice_coef': [],\n",
    "        'iou_coef': []\n",
    "    }\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, batch in pbar:\n",
    "        images, masks = batch['image'], batch['mask']\n",
    "        \n",
    "        y_pred = model.forward(images)\n",
    "        \n",
    "        loss = loss_fn(y_pred=y_pred, y_true=masks)\n",
    "            \n",
    "        running_loss += loss.item() * images.shape[0]\n",
    "        dataset_size += images.shape[0]\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        coef['dice_coef'].append(dice_coef(y_pred=y_pred, y_true=masks))\n",
    "        coef['iou_coef'].append(iou_coef(y_pred=y_pred, y_true=masks))\n",
    "        \n",
    "        pbar.set_postfix(\n",
    "            train_loss=f'{epoch_loss:.3f}',\n",
    "            dice=f'{np.mean(coef[\"dice_coef\"]):.3f}',\n",
    "            iou=f'{np.mean(coef[\"iou_coef\"]):.3f}',\n",
    "        )\n",
    "    \n",
    "    return epoch_loss, np.mean(coef['dice_coef']), np.mean(coef['iou_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4037ae",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80542f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "    model: nn.Module, optimizer: optim, \n",
    "    train_loader: DataLoader, valid_loader: DataLoader,\n",
    "    scheduler: lr_scheduler = None, fold: int = 0, num_epochs: int = 10, \n",
    "):\n",
    "    wandb.watch(model, log_freq=100)\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_dice      = -1\n",
    "    best_epoch     = -1\n",
    "    history        = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_dice, train_iou = train_one_epoch(\n",
    "            model=model, \n",
    "            optimizer=optimizer, \n",
    "            scheduler=scheduler, \n",
    "            dataloader=train_loader\n",
    "        )\n",
    "        \n",
    "        valid_loss, valid_dice, valid_iou = valid_one_epoch(\n",
    "            model=model, \n",
    "            dataloader=valid_loader\n",
    "        )\n",
    "        \n",
    "        wandb.log({\n",
    "            'Train Loss'    : train_loss, \n",
    "            'Train Dice'    : train_dice, \n",
    "            'Train IoU'     : train_iou, \n",
    "            'Valid Loss'    : valid_loss, \n",
    "            'Valid Dice'    : valid_dice,\n",
    "            'Valid IoU'     : valid_iou, \n",
    "            'Learning Rate' : scheduler.get_last_lr()[0]\n",
    "        })\n",
    "        \n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Train Dice'].append(train_dice)\n",
    "        history['Train IoU'].append(train_iou)\n",
    "        history['Valid Loss'].append(valid_loss)\n",
    "        history['Valid Dice'].append(valid_dice)\n",
    "        history['Valid IoU'].append(valid_iou)\n",
    "        \n",
    "        print(f'Validation Dice: {valid_dice:.3f}  |  Validation IoU: {valid_iou:.3f}')\n",
    "        \n",
    "        if valid_dice >= best_dice:\n",
    "            print(f'{c_}Validation Dice Score increased from {best_dice:0.4f} -> {valid_dice:0.4f}')\n",
    "            best_epoch = epoch\n",
    "            best_dice  = valid_dice\n",
    "            \n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            run.summary['Best Dice'] = best_dice\n",
    "            run.summary['Best Epoch'] = best_epoch\n",
    "            \n",
    "            model_path = f'{config.comment}-fold-{fold}.bin'\n",
    "            torch.save(best_model_wts, model_path)\n",
    "            wandb.save(model_path)\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca124c79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for fold in range(config.n_fold):\n",
    "    print('>'*15)\n",
    "    print(f'>>> Fold #{fold + 1} <<<')\n",
    "    print('<'*15)\n",
    "    \n",
    "    run = wandb.init(\n",
    "        project='uwgmi',\n",
    "        config={k:v for k, v in dict(vars(config)).items() if '__' not in k},\n",
    "        name=f'fold-{fold}|{config.comment}',\n",
    "        group=config.comment\n",
    "    )\n",
    "    \n",
    "    train_loader, valid_loader = build_dataloaders(fold=fold)\n",
    "    \n",
    "    model = build_model()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.wd)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "    \n",
    "    model, history = run_training(\n",
    "        model=model, \n",
    "        optimizer=optimizer, \n",
    "        scheduler=scheduler, \n",
    "        fold=fold, \n",
    "        num_epochs=config.epochs, \n",
    "        train_loader=train_loader, \n",
    "        valid_loader=valid_loader\n",
    "    )\n",
    "    \n",
    "    run.finish()\n",
    "    display(ipd.IFrame(run.url, width=1000, height=720))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
